{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c023073-a48d-404d-b5ae-2237ff46861c",
   "metadata": {},
   "source": [
    "### What is computer vision?\n",
    "Computer Vision is a subfield of [Deep Learning](https://github.com/letspython3x/Books/blob/master/Deep%20Learning%20with%20Python.pdf) and Artificial Intelligence, also refer [here](https://livebook.manning.com/book/grokking-deep-learning-for-computer-vision/chapter-1/66)  where humans teach computers to see and interpret the world around them.\n",
    "\n",
    "\n",
    "Image Classification is one of the most fundamental tasks in computer vision. It has revolutionized and propelled technological advancements in the most prominent fields, including the automobile industry, healthcare, manufacturing, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d8297-426a-4fad-bc74-f1e1329c5777",
   "metadata": {},
   "source": [
    "### How does image classification work?\n",
    "Image Classification (often referred to as Image Recognition) is the task of associating one (single-label classification) or more (multi-label classification) labels to a given image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86602406-a0a0-462f-a313-bc30b102b718",
   "metadata": {},
   "source": [
    "### Basic steps in computer vision:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89577d4-f50e-4fcf-8569-f7d73926efab",
   "metadata": {},
   "source": [
    "### Input Data:\n",
    "   - Loading images or videos (image frames)\n",
    "   \n",
    "### Preprocessing: \n",
    "\n",
    "   - Normalization, rescaling pixels/resizing, color transformation, one Hot encoding etc\n",
    "    \n",
    "### Feature Extraction: \n",
    "   - Finding unique characteristic/features of an image\n",
    "    \n",
    "### Modeling\n",
    "   - Learn from the extracted features to predict and classify object (source:[here](https://github.com/moelgendy/deep_learning_for_vision_systems))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77a578-9a84-4d48-b2ec-8a69e66f84f1",
   "metadata": {},
   "source": [
    "## How Computers \"See\" images?\n",
    "When we look at an image, we see objects, landscape, colors, and so on. But that’s not the case with computers. Images are just a 2D arrays of numbers of pixels (for grayscale pictures); where a pixel is simply a number represented by a range of either zero to one or in 0 to 255.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169e859-d010-4849-b1e2-8507968df8a3",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/cv1.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf428eb3-a498-47a1-90e7-511a1e6f158b",
   "metadata": {},
   "source": [
    "Fig.1 Source: [Computer vision: The power of seeing and interpreting images](https://datascience.aero/computer-vision-seeing-interpreting-images/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a7311-96d9-4542-82a5-d06798087941",
   "metadata": {},
   "source": [
    ">In grayscale images, each pixel represents the intensity of only one color, whereas in the standard RGB system, color images have three channels (red, green, and blue). In other words, color images are represented by three matrices: one represents the intensity of red in the pixel, one represents green, and one represents blue ([source](https://livebook.manning.com/book/grokking-deep-learning-for-computer-vision/chapter-1/125))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c10bd-4ed0-4564-bfb5-702a4db1c93c",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/cv2.png\" width=\"600\"/>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Fig.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c4cb0-7f65-4c4e-87e1-4cf781f22504",
   "metadata": {},
   "source": [
    ">As you can see in figure above, the color image is composed of three channels: red, green, and blue. Now the question is, how do computers see this image? Again, they see the matrix, unlike grayscale images, where we had only one channel. In this case, we will have three matrices stacked on top of each other; that’s why it’s a 3D matrix. The dimensionality of 700 × 700 color images is (700, 700, 3). Let’s say the first matrix represents the red channel; then each element of that matrix represents an intensity of red color in that pixel, and likewise with green and blue. Each pixel in a color image has three numbers (0 to 255) associated with it. These numbers represent intensity of red, green, and blue color in that particular pixel. <br>\n",
    "If we take the pixel $F(0,0)$ as an example, we will see that it represents the top-left pixel of the image of green grass. When we view this pixel in the color images, it looks like figure below which shows some shades of the color green and their RGB values ([source](https://livebook.manning.com/book/grokking-deep-learning-for-computer-vision/chapter-1/https://livebook.manning.com/book/grokking-deep-learning-for-computer-vision/chapter-1/))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6ab60-65e2-4b7e-968d-d3b54d5ef3b0",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"images/cv3.png\" width=\"300\"/>\n",
    "</div>\n",
    "<div>\n",
    "    <img src=\"images/cv17.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afff8ba-fb9a-47a1-896e-559b6221d083",
   "metadata": {},
   "source": [
    "Fig.3:  `RGB` color cobination formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653774f1-b5ed-47bb-ba61-77f220ddf05e",
   "metadata": {},
   "source": [
    "# 2. Image Preprocessing\n",
    "- Normalization, standardization, one Hot encoding etc \n",
    "Any adjustments that you need to apply to your dataset are part of preprocessing.The good news is that, unlike traditional machine learning, DL algorithms require minimum data preprocessing because neural networks do most of the heavy lifting in processing an image and extracting features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c800548-01e7-470a-a4f2-0234ed7ad49d",
   "metadata": {},
   "source": [
    "- Image processing could involve simple tasks like image resizing. In order to feed a dataset of images to a convolutional network, the images all have to be the same size.\n",
    "- Converting color images to grayscale to reduce computation complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d67de-1393-4d17-a428-7350dfdd8239",
   "metadata": {},
   "source": [
    "- Standardizing images: images must be preprocessed and scaled to have identical widths and heights before being fed to the learning algorithm.\n",
    "\n",
    "- Data augmentation --Another common preprocessing technique involves augmenting the existing dataset with modified versions of the existing images. Scaling, rotations, and other affine transformations are typically used to enlarge your dataset and expose the neural network to a wide variety of variations of your images. This makes it more likely that your model will recognize objects when they appear in any form and shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05a812-9bd9-40b2-94be-5da0a9162c6f",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/cnn16.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Fig.6. [source](https://www.kaggle.com/kedarsai/cifar-10-88-accuracy-using-keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d2002-0981-44b8-bab1-2f271d06a8cc",
   "metadata": {},
   "source": [
    "# Building Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a969a-92a2-46b2-801a-d60d42a483ac",
   "metadata": {},
   "source": [
    "* We'll get back to the ______ for the implementation of this theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176043b-1129-485d-9ebd-4a1852c64ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
