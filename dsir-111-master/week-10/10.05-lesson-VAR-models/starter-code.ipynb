{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# VAR Models\n",
    "_Author: Matt Brems_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "_By the end of the lesson, students should be able to:_\n",
    "- Describe univariate and multivariate time series.\n",
    "- Identify the advantages of working with multivariate time series.\n",
    "- Define VAR models.\n",
    "- Understand and test for the assumptions of VAR models.\n",
    "- Fit, generate predictions from, and evaluate VAR models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions to ARIMA Model\n",
    "\n",
    "As we discussed before, the ARIMA model is a very flexible model that can be extended in multiple ways.\n",
    "- Seasonal ARIMA: An ARIMA model that can account for seasonal fluctuations and differences.\n",
    "- ARIMA with eXogenous Predictors: An ARIMA model that can include eXogenous predictors (independent X variables).\n",
    "- Vector ARIMA models: An ARIMA model that can handle multivariate time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Time Series Models\n",
    "\n",
    "**Univariate** time series methods are those that deal with forecasting one variable into the future.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "Y^{(d)}_t = AR(p) + MA(q) + \\text{seasonal component} + X_{1, t-1} + X_{2, t-1} + X_{3, t-1}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "In this situation, we're taking three independent variables ($X_1$, $X_2$, $X_3$) and using them to predict $Y$. However, if $X_1$, $X_2$, $X_3$ are related to $Y$, does it make sense to forecast $X_1$, $X_2$, $X_3$ forward as well?\n",
    "\n",
    "**Multivariate** time series methods are those that deal with forecasting multiple variable into the future.\n",
    "\n",
    "Let's relabel $X_1$, $X_2$, $X_3$ as $Y_2$, $Y_3$, $Y_4$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{original series: } Y^{(d)}_{1,t} &=& AR(p) + MA(q) + \\text{seasonal component} + Y_{2, t-1} + Y_{3, t-1} + Y_{4, t-1} \\\\\n",
    "\\\\\n",
    "Y^{(d)}_{2,t} &=& AR(p) + MA(q) + \\text{seasonal component} + Y_{1, t-1} + Y_{3, t-1} + Y_{4, t-1} \\\\\n",
    "\\\\\n",
    "Y^{(d)}_{3,t} &=& AR(p) + MA(q) + \\text{seasonal component} + Y_{1, t-1} + Y_{2, t-1} + Y_{4, t-1} \\\\\n",
    "\\\\\n",
    "Y^\n",
    "{(d)}_{4,t} &=& AR(p) + MA(q) + \\text{seasonal component} + Y_{1, t-1} + Y_{2, t-1} + Y_{3, t-1} \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "This makes the most sense as a strategy when our variables are all related. \n",
    "- $Y_1$ is related to $Y_2$, $Y_3$, $Y_4$,\n",
    "- $Y_2$ is related to $Y_1$, $Y_3$, $Y_4$,\n",
    "- and so on.\n",
    "\n",
    "The most common method of tackling this is to use VAR models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR Time Series Models\n",
    "\n",
    "VAR time series models are **vector autoregressive models**.\n",
    "- Rather than regressing one time series $Y_t$ on lagged versions of itself and on lagged versions of independent variables $X$, we will take all of our variables $Y_{1,t}, Y_{2,t}, Y_{3,t}, \\ldots$ and regress them on one another simultaneously.\n",
    "- This allows us to forecast forward many variables simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What are examples of variables we may want to forecast forward together?</summary>\n",
    "    \n",
    "_(Answers may vary.)_\n",
    "\n",
    "- Prevalence of multiple pollutants (like chemicals from factories).\n",
    "- Exchange rates between countries. (e.g. USD to EUR, EUR to CHF, CHF to GBP, GBP to USD.)\n",
    "- Macroeconomic indices (like GDP and unemployment rate) that may influence one another.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VAR\n",
    "from statsmodels.tsa.api import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the macroeconomic data.\n",
    "df ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We'll be using [U.S. Macroeconomic data](https://www.statsmodels.org/0.6.1/datasets/generated/macrodata.html) that is available via the `statsmodels` package. This is quarter-level data from 1959 to 2009.\n",
    "- `year`: the year the data was measured.\n",
    "- `quarter`: the quarter the data was measured.\n",
    "- `realgdp`: real gross domestic product (in billions, in 2005 US dollars).\n",
    "- `pop`: total population measured at the end of the quarter (includes all ages and overseas armed forces members).\n",
    "- `unemp`: seasonally adjusted unemployment rate (in percent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array called \"dates\" based on \"year\" and \"quarter.\"\n",
    "dates =\n",
    "\n",
    "# Create a vector called \"quarterly\" combining year and quarter together.\n",
    "quarterly = \n",
    "\n",
    "# Import dates_from_str and convert \"quarterly\" into dates.\n",
    "from statsmodels.tsa.base.datetools import dates_from_str\n",
    "quarterly = dates_from_str(quarterly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the realgdp, pop, unemp columns.\n",
    "df = df[['realgdp','pop','unemp']]\n",
    "\n",
    "# Set index to be \"quarterly.\"\n",
    "df.index =\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code modified from code written by Matthew Garton.\n",
    "\n",
    "def plot_series(df, cols=None, title='Title', xlab=None, ylab=None, steps=1):\n",
    "    \n",
    "    # Set figure size to be (18, 9).\n",
    "    plt.figure(figsize=(18,9))\n",
    "    \n",
    "    # Iterate through each column name.\n",
    "    for col in cols:\n",
    "            \n",
    "        # Generate a line plot of the column name.\n",
    "        # You only have to specify Y, since our\n",
    "        # index will be a datetime index.\n",
    "        plt.plot(df[col])\n",
    "        \n",
    "    # Generate title and labels.\n",
    "    plt.title(title, fontsize=26)\n",
    "    plt.xlabel(xlab, fontsize=20)\n",
    "    plt.ylabel(ylab, fontsize=20)\n",
    "    \n",
    "    # Enlarge tick marks.\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xticks(df.index[0::steps], fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our real GDP data.\n",
    "plot_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our population data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our unemployment data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting Process\n",
    "1. Confirm stationarity of the data.\n",
    "2. Train/test split.\n",
    "3. Determine correct lag order $p$.\n",
    "4. Fit model.\n",
    "5. Generate forecasts.\n",
    "6. Evaluate model and forecasts (if possible).\n",
    "\n",
    "#### 1. Confirm stationarity of the data.\n",
    "Vector autoregressive models require stationarity in order for us to fit them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>How would you describe stationarity?</summary>\n",
    "\n",
    "- When our time series does not have systematic changes over time.\n",
    "- Constant mean, correlation that only depends on lag (and not point in time).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What do we use to check whether or not a time series is stationary?</summary>\n",
    "\n",
    "- Augmented Dickey-Fuller test!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code written by Joseph Nelson.\n",
    "\n",
    "def interpret_dftest(dftest):\n",
    "    dfoutput = pd.Series(dftest[0:2], index=['Test Statistic','p-value'])\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run ADF test on the original Real GDP data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Based on the results here, what action should we take?</summary>\n",
    "\n",
    "- Difference our data.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming $\\alpha=0.01$, take two minutes to achieve stationarity for `pop` and `unemp`. If needed, create the columns we want to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset our data.\n",
    "df = df[['first_diff_realgdp', 'second_diff_pop', 'first_diff_unemp']]\n",
    "\n",
    "# Let's get rid of rows containing missing values.\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What am I missing?\n",
    "\n",
    "train, test = train_test_split(df,\n",
    "                               test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Determine correct lag order $p$.\n",
    "\n",
    "We can check out autocorrelation plots and partial autocorrelation plots to attempt to figure out how many previous values of **each variable** we want in our model.\n",
    "\n",
    "Suppose I select $p=2$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "Y^{(d)}_{1,t} &=& \\beta_0 + \\beta_1Y^{(d)}_{1,t-1} + \\beta_2Y^{(d)}_{1,t-2} + \\beta_3Y^{(d)}_{2,t-1} + \\beta_4Y^{(d)}_{2,t-2} + \\beta_5Y^{(d)}_{3,t-1} + \\beta_6Y^{(d)}_{3,t-2} \\\\\n",
    "\\\\\n",
    "Y^{(d)}_{2,t} &=& \\gamma_0 + \\gamma_1Y^{(d)}_{1,t-1} + \\gamma_2Y^{(d)}_{1,t-2} + \\gamma_3Y^{(d)}_{2,t-1} + \\gamma_4Y^{(d)}_{2,t-2} + \\gamma_5Y^{(d)}_{3,t-1} + \\gamma_6Y^{(d)}_{3,t-2} \\\\\n",
    "\\\\\n",
    "Y^{(d)}_{3,t} &=& \\delta_0 + \\delta_1Y^{(d)}_{1,t-1} + \\delta_2Y^{(d)}_{1,t-2} + \\delta_3Y^{(d)}_{2,t-1} + \\delta_4Y^{(d)}_{2,t-2} + \\delta_5Y^{(d)}_{3,t-1} + \\delta_6Y^{(d)}_{3,t-2}\n",
    "\\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "However, we can automate the selection of $p$ using a metric called the Akaike information criterion, or the AIC.\n",
    "\n",
    "##### AIC\n",
    "\n",
    "The AIC is a metric that is commonly used for time series models or in more \"statistics-oriented\" fields.\n",
    "- Recall that models are just simplifications of reality. AIC attempts to measure how much information we lose when we simplify reality with a model.\n",
    "- The lower the AIC, the better!\n",
    "- More details can be found at the [Wikipedia page](https://en.wikipedia.org/wiki/Akaike_information_criterion).\n",
    "\n",
    "We can actually find a good value of $p$ when we fit our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a VAR model. Remember that we pass\n",
    "# our data in during instantiation in statsmodels!\n",
    "model ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model and use AIC to select the value of p.\n",
    "\n",
    "ts_model = model.fit(, # what is the largest possible value of p?\n",
    "                     )   # what \"information criterion\" (ic) will we use to decide what's \"best?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the order of our autoregressive model? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the summary of our model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our training data.\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Generate forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the forecast looking 3 steps ahead.\n",
    "ts_model.plot_forecast(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast looking 50 steps ahead.\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a forecast one step ahead.\n",
    "ts_model.forecast(train.values, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a forecast five steps ahead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a forecast that matches our testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the values of our test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Evaluate model (and forecasts, if possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use MSE to evaluate our models.\n",
    "\n",
    "# Save our forecast as forecast.\n",
    "forecast = ts_model.forecast(train.values, len(test))\n",
    "\n",
    "# Instantiate MSE values at 0.\n",
    "mse_gdp = 0\n",
    "mse_pop = 0\n",
    "mse_unemp = 0\n",
    "\n",
    "# Loop through each forecasted time point.\n",
    "for time in range(len(test)):\n",
    "    \n",
    "    # Calculate (expected - observed) ** 2 and add to MSE.\n",
    "    mse_gdp += (forecast[time][0] - test.values[time][0]) ** 2\n",
    "    mse_pop += (forecast[time][1] - test.values[time][1]) ** 2\n",
    "    mse_unemp += (forecast[time][2] - test.values[time][2]) ** 2\n",
    "\n",
    "# Divide SSE to get MSE.\n",
    "mse_gdp /= len(test)\n",
    "mse_pop /= len(test)\n",
    "mse_unemp /= len(test)\n",
    "    \n",
    "# Generate output.    \n",
    "print(f'The test MSE on the Real GDP data is: {round(mse_gdp, 4)}')\n",
    "print(f'The test MSE on the population data is: {round(mse_pop, 4)}')\n",
    "print(f'The test MSE on the unemployment data is: {round(mse_unemp, 4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
