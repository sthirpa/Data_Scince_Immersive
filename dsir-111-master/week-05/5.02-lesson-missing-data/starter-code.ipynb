{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Missing Data\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Define MCAR, MAR, and NMAR.\n",
    "- Describe various strategies for dealing with missing data.\n",
    "- Understand the assumptions we make when using strategies to handle missing data.\n",
    "\n",
    "### Credit\n",
    "This lesson is adapted from a missing data workshop that Matt Brems presented at the Open Data Science Conference ([ODSC](https://odsc.com/)).  Check out his GitHub repo [here](https://github.com/matthewbrems/missing-data-workshop?fbclid=IwAR1LGjaIen-ITLndPN1ODV1lYZBvxsHDs0DgIaPkuxpXMsQRBT8eAPI-0sI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "# Set random seed.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in our data of age, partnered, children, and income data\n",
    "# where income is linearly related to age, partnered, and children.\n",
    "income = pd.read_csv('../data/income.csv') \n",
    "income_missing = pd.read_csv('../data/income_missing.csv') \n",
    "\n",
    "# Check out first 10 rows\n",
    "income_missing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to compare histograms of original & imputed data\n",
    "def compare_histograms(imputed_column, original_column, x_label, y_label = 'Frequency'):\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows = 2, ncols = 1, figsize = (16,9))\n",
    "\n",
    "    # Set axes of histograms.\n",
    "    mode = statistics.mode(imputed_column)\n",
    "    rnge = max(original_column) - min(original_column)\n",
    "    xmin = min(original_column) - 0.02 * rnge\n",
    "    xmax = max(original_column) + 0.02 * rnge\n",
    "    ymax = 40\n",
    "\n",
    "    ax0.set_xlim(xmin, xmax)\n",
    "    ax0.set_ylim(0, ymax)\n",
    "    ax1.set_xlim(xmin, xmax)\n",
    "    ax1.set_ylim(0, ymax)\n",
    "\n",
    "    # Set top labels.\n",
    "    ax0.set_title('Real Histogram', position = (0,1), ha = 'left', fontsize = 25)\n",
    "    ax0.set_xlabel(x_label, position = (0,0), ha = 'left', fontsize = 25, color = 'grey', alpha = 0.85)\n",
    "    ax0.set_ylabel(y_label, position = (0,1), ha = 'right', va = 'top', fontsize = 25, rotation = 0, color = 'grey', alpha = 0.85)\n",
    "    ax0.set_xticks([])\n",
    "    ax0.set_yticks([])\n",
    "\n",
    "    # Generate top histogram.\n",
    "    ax0.hist(original_column, bins = 15, color = '#185fad', alpha = 0.75, label = '')\n",
    "    ax0.axvline(np.mean(original_column), color = '#185fad', lw = 5, label = 'True Mean')\n",
    "    ax0.legend(prop={'size': 15}, loc = 1)\n",
    "\n",
    "    # Set bottom labels.\n",
    "    ax1.set_title('Imputed Histogram', position = (0,1), ha = 'left', fontsize = 25)\n",
    "    ax1.set_xlabel(x_label, position = (0,0), ha = 'left', fontsize = 25, color = 'grey', alpha = 0.85)\n",
    "    ax1.set_ylabel(y_label, position = (0,1), ha = 'right', va = 'top', fontsize = 25, rotation = 0, color = 'grey', alpha = 0.85)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    # Generate bottom histogram.\n",
    "    ax1.hist(imputed_column, bins = 15, color = 'orange', alpha = 0.75, label = '', stacked = True)\n",
    "    ax1.axvline(np.mean(original_column), color = '#185fad', lw = 5, label = 'True Mean')\n",
    "    ax1.axvline(np.mean(imputed_column), color = 'darkorange', lw = 5, label = 'Imputed Mean')\n",
    "    ax1.legend(prop={'size': 15}, loc = 1)\n",
    "\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Deductive Imputation\n",
    "\n",
    "We use logical rules to fill in missing values.\n",
    "- Survey asks if the respondent was the victim of a crime in the last twelve months.\n",
    "- Respondent says no.\n",
    "- Survey then asks if the respondent was the victim of a violent crime in the last twelve months.\n",
    "- Respondent leaves this answer blank.\n",
    "\n",
    "**Pros**:\n",
    "- Can be used regardless of missingness type\n",
    "- Requires no inference\n",
    "\n",
    "**Cons**:\n",
    "- Requires specific coding\n",
    "- Can be time consuming\n",
    "- May not be possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Mean/Median/Mode Imputation\n",
    "\n",
    "For any “NA” value in a given column, replace “NA” with the mean, median, or mode.\n",
    "\n",
    "**Pros**:\n",
    "- Quick\n",
    "- Easy to implement\n",
    "- Seems reasonable\n",
    "\n",
    "**Cons**:\n",
    "- Can significantly distort histogram\n",
    "- Underestimates variance\n",
    "- Should only be considered if data is MCAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Which columns have missing values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's impute missing values in the age column with the mean\n",
    "mean_age = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_histograms(imputed_column = income_missing['age_mean_imputed'],\n",
    "                   original_column = income['age'],\n",
    "                   x_label = 'Age',\n",
    "                   y_label = 'Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are underestimating the variance here.\n",
    "\n",
    "\n",
    "Why is this a bad thing?\n",
    "- If we underestimate variance in a confidence interval, our confidence interval gets smaller for the same level of confidence!\n",
    "    - Our results artificially look more precise... but only because we imputed the mean!\n",
    "- If we underestimate the variance in a hypothesis test, our p-value will artificially get smaller.\n",
    "    - Our p-value may look significant... but only because we imputed the mean!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's impute missing values in the age column with the median\n",
    "med_age = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's impute missing values in the age column with the mode\n",
    "mode_age = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make your life easier -> Simple Imputer in sklearn\n",
    "\n",
    "Note: Train-test-split BEFORE doing this if you are going to model later to avoid data leakage!\n",
    "\n",
    "Documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import simple imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Single Regression Imputation\n",
    "\n",
    "Train a model on the rows of your data that are fully observed.\n",
    "- Suppose I’m missing income for some people, but have observed age and highest level of education for everybody.\n",
    "- X = age and highest level of education, Y = income.\n",
    "- Fit a model.\n",
    "- For any “NA” value in a given column, replace “NA” with predicted value from that model.\n",
    "\n",
    "**Pros**:\n",
    "- Seems reasonable\n",
    "- A little more nuanced than mean/median/mode imputation\n",
    "\n",
    "**Cons**:\n",
    "- Still distorts histogram\n",
    "- Underestimates variance\n",
    "- Should only be considered if data is MCAR or MAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data\n",
    "income_missing = pd.read_csv('../data/income_missing.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new dataframe without any missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "\n",
    "\n",
    "# Instantiate\n",
    "\n",
    "# Fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indices of missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with the prediciton from the model\n",
    "income_missing['age_regression_imputed'] = [income_missing.loc[i,'age'] if i not in missing_idx\n",
    "     else model.predict(pd.DataFrame(income_missing.loc[i,['children', 'partnered', 'income']]).T)[0]\n",
    "     for i in range(income_missing.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_histograms(imputed_column = income_missing['age_regression_imputed'],\n",
    "                   original_column = income['age'],\n",
    "                   x_label = 'Age',\n",
    "                   y_label = 'Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/deterministic_imputation.png)\n",
    "\n",
    "[source](http://www.stat.columbia.edu/~gelman/arm/missing.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make your life easier -> Iterative Imputer in sklearn\n",
    "\n",
    "Documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer).\n",
    "\n",
    "From [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer): \n",
    "> Note: This estimator is still experimental for now: the predictions and the API might change without any deprecation cycle. To use it, you need to explicitly import enable_iterative_imputer:\n",
    "\n",
    "```python\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "```\n",
    "\n",
    "Again, make sure to fit this only on training data if you are using this for a model (you can transform testing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data\n",
    "income_missing = pd.read_csv('../data/income_missing.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it with the defaul model\n",
    "income_missing = pd.read_csv('../data/income_missing.csv') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Nearest Neighbors Imputation\n",
    "\n",
    "Documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import it\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data\n",
    "income_missing = pd.read_csv('../data/income_missing.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: Multiple Imputation\n",
    "\n",
    "If we want to account for the randomness in our data, we can fill in missing values with some amount of randomness/uncertainty.\n",
    "\n",
    "Replacing an NA with one value treats things like we know the true value.\n",
    "\n",
    "Therefore, we need to impute multiple times.\n",
    "- We will make multiple copies (say 10) of our dataset.\n",
    "- We will use [random regression imputation](https://statisticsglobe.com/regression-imputation-stochastic-vs-deterministic/) to generate one value for each NA in each dataset.\n",
    "- Once each of our 10 datasets are complete, we will do our “final model” or “final analysis” on each dataset.\n",
    "- We will then combine the results of our multiple models together, just like we aggregate results in an ensemble model.\n",
    "\n",
    "![](../images/proper_imputation.png)\n",
    "\n",
    "\n",
    "If you’re **generating predictions**, you can just average your predictions together in a regression problem or select the plurality class in a classification problem.\n",
    "\n",
    "If your goal is to do **inference** (e.g. understand how X affects Y) and are fitting a linear model to each dataset, then you get a slope and y-intercept for each model.\n",
    "- There are a set of tools, called Rubin’s rules, that will allow you to take the slopes and y-intercepts from each model and combine them together.\n",
    "- Check out documentation in the repo if interested!\n",
    "\n",
    "[IterativeImputer](https://scikit-learn.org/stable/modules/impute.html#multiple-vs-single-imputation) in sklearn can help with this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Indicator Column\n",
    "\n",
    "We can add a column about which values were imputed/missing and use that as a feature in our model. This can help when there is a pattern in what is missing and our target and may help our model.\n",
    "\n",
    "See another example of this [here](https://nbviewer.jupyter.org/github/justmarkham/scikit-learn-tips/blob/master/notebooks/09_add_missing_indicator.ipynb).\n",
    "\n",
    "There are several ways we can do this:\n",
    "1. Set `add_indicator = True` in Simple Imputer or Iterative Imputer if you are using these:\n",
    "```python\n",
    "imputer = SimpleImputer(add_indicator=True)\n",
    "imputer.fit_transform(X)\n",
    "```\n",
    "2. Use the `MissingIndicator` transformer in [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html#sklearn.impute.MissingIndicator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data\n",
    "income_missing = pd.read_csv('../data/income_missing.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### To the slides!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Pattern Submodel Approach\n",
    "\n",
    "Big Picture: We will break our dataset into subsets based on missingness pattern. We will then build one model on each subset, creating many different models.\n",
    "\n",
    "![](./images/pattern_submodel.jpeg)\n",
    "\n",
    "[image source](https://opendatascience.com/data-imputation-beyond-mean-median-and-mode/)\n",
    "\n",
    "**Pros**:\n",
    "- The pattern submodel method will outperform imputation methods when your data are NMAR, and will perform about as well as imputation methods when your data are MCAR or MAR.\n",
    "- You can generate predictions for test observations containing missing data.\n",
    "- It does not require missingness assumptions!\n",
    "\n",
    "**Cons**:\n",
    "- This is not a well-understood method for inference.\n",
    "\n",
    "Read more about this method [here](https://academic.oup.com/biostatistics/article/21/2/236/5092384).\n",
    "\n",
    "See an example of this [here](https://github.com/sarahmercaldo/MissingDataAndPrediction) - note that this example is done in R."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
