# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Cross Validation, Train-Test-Split

## Materials We Provide


| Topic | Description | Link |
| --- | --- | --- |
| Lesson | Cross Validation/Train Test Split | [Link](./starter-code.ipynb)|

---

## Learning Objectives
*After this lesson, you will be able to:*

- Describe train/test split and cross-validation.
- Explain how these validation techniques differ and why we want to use them.
- Split data into testing and training sets using both train/test split and cross-validation and apply both techniques to score a model.
---

## Lesson Outline

> **Estimated Total Time: 90 mins**

I. **Cross Validation/Train Test Split**
- Overfitting and Underfitting
- Importing libraries and loading data
- Data cleaning
- EDA
- Train/Test Split and Model Validation
- K-Fold Cross Validation
- Holdout Sets

---

## Additional Resources

- [Cross-Validation Example](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py).
- Examine this [academic paper](http://frostiebek.free.fr/docs/Machine%20Learning/validation-1.pdf) on the underpinnings of the holdout method, LOOVC, and kfolds
- The sklearn [documentation](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) on cross validation is strong
- This [Stanford lesson](https://www.youtube.com/watch?v=_2ij6eaaSl0) on cross validation
- This [blog post](http://www.win-vector.com/blog/2015/01/random-testtrain-split-is-not-always-enough/) on why TTS is not always enough
- StackExchange [discussion](http://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio) on approximate TTS, validation set sizes
___
