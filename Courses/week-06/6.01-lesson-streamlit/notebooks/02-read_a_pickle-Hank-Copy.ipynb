{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model in a new notebook\n",
    "\n",
    "Here, we'll import our fitted pipeline and use it to make predictions about brand new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a `with` statement to import the pickled pipeline and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/author_pipe.pkl', 'rb') as pickle_in:\n",
    "    pipe = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the pipeline. Does it still have the attributes and methods we'd expect it to have? ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Edgar Allan Poe', 'Jane Austen'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Pipeline in module sklearn.pipeline object:\n",
      "\n",
      "class Pipeline(sklearn.utils.metaestimators._BaseComposition)\n",
      " |  Pipeline(steps, *, memory=None, verbose=False)\n",
      " |  \n",
      " |  Pipeline of transforms with a final estimator.\n",
      " |  \n",
      " |  Sequentially apply a list of transforms and a final estimator.\n",
      " |  Intermediate steps of the pipeline must be 'transforms', that is, they\n",
      " |  must implement `fit` and `transform` methods.\n",
      " |  The final estimator only needs to implement `fit`.\n",
      " |  The transformers in the pipeline can be cached using ``memory`` argument.\n",
      " |  \n",
      " |  The purpose of the pipeline is to assemble several steps that can be\n",
      " |  cross-validated together while setting different parameters. For this, it\n",
      " |  enables setting parameters of the various steps using their names and the\n",
      " |  parameter name separated by a `'__'`, as in the example below. A step's\n",
      " |  estimator may be replaced entirely by setting the parameter with its name\n",
      " |  to another estimator, or a transformer removed by setting it to\n",
      " |  `'passthrough'` or `None`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <pipeline>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.5\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  steps : list of tuple\n",
      " |      List of (name, transform) tuples (implementing `fit`/`transform`) that\n",
      " |      are chained, in the order in which they are chained, with the last\n",
      " |      object an estimator.\n",
      " |  \n",
      " |  memory : str or object with the joblib.Memory interface, default=None\n",
      " |      Used to cache the fitted transformers of the pipeline. By default,\n",
      " |      no caching is performed. If a string is given, it is the path to\n",
      " |      the caching directory. Enabling caching triggers a clone of\n",
      " |      the transformers before fitting. Therefore, the transformer\n",
      " |      instance given to the pipeline cannot be inspected\n",
      " |      directly. Use the attribute ``named_steps`` or ``steps`` to\n",
      " |      inspect estimators within the pipeline. Caching the\n",
      " |      transformers is advantageous when fitting is time consuming.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      If True, the time elapsed while fitting each step will be printed as it\n",
      " |      is completed.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  named_steps : :class:`~sklearn.utils.Bunch`\n",
      " |      Dictionary-like object, with the following attributes.\n",
      " |      Read-only attribute to access any step parameter by user given name.\n",
      " |      Keys are step names and values are steps parameters.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. Only exist if the last step of the pipeline is a\n",
      " |      classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if the\n",
      " |      underlying first estimator in `steps` exposes such an attribute\n",
      " |      when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if the\n",
      " |      underlying estimator exposes such an attribute when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  make_pipeline : Convenience function for simplified pipeline construction.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> from sklearn.pipeline import Pipeline\n",
      " |  >>> X, y = make_classification(random_state=0)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
      " |  ...                                                     random_state=0)\n",
      " |  >>> pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
      " |  >>> # The pipeline can be used as any other estimator\n",
      " |  >>> # and avoids leaking the test set into the train set\n",
      " |  >>> pipe.fit(X_train, y_train)\n",
      " |  Pipeline(steps=[('scaler', StandardScaler()), ('svc', SVC())])\n",
      " |  >>> pipe.score(X_test, y_test)\n",
      " |  0.88\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Pipeline\n",
      " |      sklearn.utils.metaestimators._BaseComposition\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, ind)\n",
      " |      Returns a sub-pipeline or a single estimator in the pipeline\n",
      " |      \n",
      " |      Indexing with an integer will return an estimator; using a slice\n",
      " |      returns another Pipeline instance which copies a slice of this\n",
      " |      Pipeline. This copy is shallow: modifying (or fitting) estimators in\n",
      " |      the sub-pipeline will affect the larger pipeline and vice-versa.\n",
      " |      However, replacing a value in `step` will not affect a copy.\n",
      " |  \n",
      " |  __init__(self, steps, *, memory=None, verbose=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the length of the Pipeline\n",
      " |  \n",
      " |  __sklearn_is_fitted__(self)\n",
      " |      Indicate whether pipeline has been fit.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Transform the data, and apply `decision_function` with the final estimator.\n",
      " |      \n",
      " |      Call `transform` of each transformer in the pipeline. The transformed\n",
      " |      data are finally passed to the final estimator that calls\n",
      " |      `decision_function` method. Only valid if the final estimator\n",
      " |      implements `decision_function`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements of first step\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples, n_classes)\n",
      " |          Result of calling `decision_function` on the final estimator.\n",
      " |  \n",
      " |  fit(self, X, y=None, **fit_params)\n",
      " |      Fit the model.\n",
      " |      \n",
      " |      Fit all the transformers one after the other and transform the\n",
      " |      data. Finally, fit the transformed data using the final estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Training data. Must fulfill input requirements of first step of the\n",
      " |          pipeline.\n",
      " |      \n",
      " |      y : iterable, default=None\n",
      " |          Training targets. Must fulfill label requirements for all steps of\n",
      " |          the pipeline.\n",
      " |      \n",
      " |      **fit_params : dict of string -> object\n",
      " |          Parameters passed to the ``fit`` method of each step, where\n",
      " |          each parameter name is prefixed such that parameter ``p`` for step\n",
      " |          ``s`` has key ``s__p``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Pipeline with fitted steps.\n",
      " |  \n",
      " |  fit_predict(self, X, y=None, **fit_params)\n",
      " |      Transform the data, and apply `fit_predict` with the final estimator.\n",
      " |      \n",
      " |      Call `fit_transform` of each transformer in the pipeline. The\n",
      " |      transformed data are finally passed to the final estimator that calls\n",
      " |      `fit_predict` method. Only valid if the final estimator implements\n",
      " |      `fit_predict`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Training data. Must fulfill input requirements of first step of\n",
      " |          the pipeline.\n",
      " |      \n",
      " |      y : iterable, default=None\n",
      " |          Training targets. Must fulfill label requirements for all steps\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      **fit_params : dict of string -> object\n",
      " |          Parameters passed to the ``fit`` method of each step, where\n",
      " |          each parameter name is prefixed such that parameter ``p`` for step\n",
      " |          ``s`` has key ``s__p``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray\n",
      " |          Result of calling `fit_predict` on the final estimator.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit the model and transform with the final estimator.\n",
      " |      \n",
      " |      Fits all the transformers one after the other and transform the\n",
      " |      data. Then uses `fit_transform` on transformed data with the final\n",
      " |      estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Training data. Must fulfill input requirements of first step of the\n",
      " |          pipeline.\n",
      " |      \n",
      " |      y : iterable, default=None\n",
      " |          Training targets. Must fulfill label requirements for all steps of\n",
      " |          the pipeline.\n",
      " |      \n",
      " |      **fit_params : dict of string -> object\n",
      " |          Parameters passed to the ``fit`` method of each step, where\n",
      " |          each parameter name is prefixed such that parameter ``p`` for step\n",
      " |          ``s`` has key ``s__p``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_transformed_features)\n",
      " |          Transformed samples.\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Transform input features using the pipeline.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Transformed feature names.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Returns the parameters given in the constructor as well as the\n",
      " |      estimators contained within the `steps` of the `Pipeline`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Apply `inverse_transform` for each step in a reverse order.\n",
      " |      \n",
      " |      All estimators in the pipeline must support `inverse_transform`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : array-like of shape (n_samples, n_transformed_features)\n",
      " |          Data samples, where ``n_samples`` is the number of samples and\n",
      " |          ``n_features`` is the number of features. Must fulfill\n",
      " |          input requirements of last step of pipeline's\n",
      " |          ``inverse_transform`` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_features)\n",
      " |          Inverse transformed data, that is, data in the original feature\n",
      " |          space.\n",
      " |  \n",
      " |  predict(self, X, **predict_params)\n",
      " |      Transform the data, and apply `predict` with the final estimator.\n",
      " |      \n",
      " |      Call `transform` of each transformer in the pipeline. The transformed\n",
      " |      data are finally passed to the final estimator that calls `predict`\n",
      " |      method. Only valid if the final estimator implements `predict`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements of first step\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      **predict_params : dict of string -> object\n",
      " |          Parameters to the ``predict`` called at the end of all\n",
      " |          transformations in the pipeline. Note that while this may be\n",
      " |          used to return uncertainties from some models with return_std\n",
      " |          or return_cov, uncertainties that are generated by the\n",
      " |          transformations in the pipeline are not propagated to the\n",
      " |          final estimator.\n",
      " |      \n",
      " |          .. versionadded:: 0.20\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray\n",
      " |          Result of calling `predict` on the final estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X, **predict_log_proba_params)\n",
      " |      Transform the data, and apply `predict_log_proba` with the final estimator.\n",
      " |      \n",
      " |      Call `transform` of each transformer in the pipeline. The transformed\n",
      " |      data are finally passed to the final estimator that calls\n",
      " |      `predict_log_proba` method. Only valid if the final estimator\n",
      " |      implements `predict_log_proba`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements of first step\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      **predict_log_proba_params : dict of string -> object\n",
      " |          Parameters to the ``predict_log_proba`` called at the end of all\n",
      " |          transformations in the pipeline.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_log_proba : ndarray of shape (n_samples, n_classes)\n",
      " |          Result of calling `predict_log_proba` on the final estimator.\n",
      " |  \n",
      " |  predict_proba(self, X, **predict_proba_params)\n",
      " |      Transform the data, and apply `predict_proba` with the final estimator.\n",
      " |      \n",
      " |      Call `transform` of each transformer in the pipeline. The transformed\n",
      " |      data are finally passed to the final estimator that calls\n",
      " |      `predict_proba` method. Only valid if the final estimator implements\n",
      " |      `predict_proba`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements of first step\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      **predict_proba_params : dict of string -> object\n",
      " |          Parameters to the `predict_proba` called at the end of all\n",
      " |          transformations in the pipeline.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_proba : ndarray of shape (n_samples, n_classes)\n",
      " |          Result of calling `predict_proba` on the final estimator.\n",
      " |  \n",
      " |  score(self, X, y=None, sample_weight=None)\n",
      " |      Transform the data, and apply `score` with the final estimator.\n",
      " |      \n",
      " |      Call `transform` of each transformer in the pipeline. The transformed\n",
      " |      data are finally passed to the final estimator that calls\n",
      " |      `score` method. Only valid if the final estimator implements `score`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements of first step\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      y : iterable, default=None\n",
      " |          Targets used for scoring. Must fulfill label requirements for all\n",
      " |          steps of the pipeline.\n",
      " |      \n",
      " |      sample_weight : array-like, default=None\n",
      " |          If not None, this argument is passed as ``sample_weight`` keyword\n",
      " |          argument to the ``score`` method of the final estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Result of calling `score` on the final estimator.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Transform the data, and apply `score_samples` with the final estimator.\n",
      " |      \n",
      " |      Call `transform` of each transformer in the pipeline. The transformed\n",
      " |      data are finally passed to the final estimator that calls\n",
      " |      `score_samples` method. Only valid if the final estimator implements\n",
      " |      `score_samples`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements of first step\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          Result of calling `score_samples` on the final estimator.\n",
      " |  \n",
      " |  set_params(self, **kwargs)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      Valid parameter keys can be listed with ``get_params()``. Note that\n",
      " |      you can directly set the parameters of the estimators contained in\n",
      " |      `steps`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict\n",
      " |          Parameters of this estimator or parameters of estimators contained\n",
      " |          in `steps`. Parameters of the steps may be set using its name and\n",
      " |          the parameter name separated by a '__'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Pipeline class instance.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform the data, and apply `transform` with the final estimator.\n",
      " |      \n",
      " |      Call `transform` of each transformer in the pipeline. The transformed\n",
      " |      data are finally passed to the final estimator that calls\n",
      " |      `transform` method. Only valid if the final estimator\n",
      " |      implements `transform`.\n",
      " |      \n",
      " |      This also works where final estimator is `None` in which case all prior\n",
      " |      transformations are applied.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to transform. Must fulfill input requirements of first step\n",
      " |          of the pipeline.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_transformed_features)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  classes_\n",
      " |      The classes labels. Only exist if the last step is a classifier.\n",
      " |  \n",
      " |  feature_names_in_\n",
      " |      Names of features seen during first step `fit` method.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during first step `fit` method.\n",
      " |  \n",
      " |  named_steps\n",
      " |      Access the steps by name.\n",
      " |      \n",
      " |      Read-only attribute to access any step by given name.\n",
      " |      Keys are steps names and values are the steps objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.utils.metaestimators._BaseComposition:\n",
      " |  \n",
      " |  __annotations__ = {'steps': typing.List[typing.Any]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we generate a prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jane Austen'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(['It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Edgar Allan Poe'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(['quote the raven nevermore or something like that'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we generate predictions interactively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what does this do?\n"
     ]
    }
   ],
   "source": [
    "user_text = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what does this do?\n"
     ]
    }
   ],
   "source": [
    "print(user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter some text:  West Philadelphia born and raised\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You write like: Edgar Allan Poe\n"
     ]
    }
   ],
   "source": [
    "user_text = input('Enter some text: ')\n",
    "\n",
    "prediction = pipe.predict([user_text])[0]\n",
    "\n",
    "print(f'You write like: {prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
